{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37097ac6-a6ca-4698-af7c-43c59f8f3f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdb53989-0d17-4bd0-8de5-f069101ad239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7937f9e-d68f-453c-8d5b-ccb7140ec96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 2.7.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Load the model and move it to the GPU\n",
    "model = SentenceTransformer(\"Snowflake/snowflake-arctic-embed-s\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Load your data\n",
    "file_path = 'C:/Users/user/OneDrive - Oulun yliopisto/Documents/suomi24/Data/suomi24.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "texts = data['processed_text'].tolist()\n",
    "\n",
    "# Generate embeddings in batches\n",
    "batch_size = 10000\n",
    "embeddings = []\n",
    "\n",
    "for i in tqdm(range(0, len(texts), batch_size), desc=\"Processing batches\"):\n",
    "    batch_texts = texts[i:i + batch_size]\n",
    "    batch_embeddings = model.encode(batch_texts, convert_to_tensor=True, device=device)\n",
    "    batch_embeddings = batch_embeddings.cpu().numpy()  # Move embeddings back to CPU\n",
    "    embeddings.append(batch_embeddings)\n",
    "\n",
    "# Concatenate all embeddings\n",
    "embeddings = np.vstack(embeddings)\n",
    "\n",
    "# Save embeddings to disk\n",
    "with open('embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "\n",
    "print(\"Embeddings generated and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae99a20e-56ee-41e2-ac06-a8432904ec03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
